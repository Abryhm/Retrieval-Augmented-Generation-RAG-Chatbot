{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q chromadb httpx tldextract sanic llama_index jsonify sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.1.14 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (0.1.14)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain==0.1.14) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain==0.1.14) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain==0.1.14) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain==0.1.14) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain==0.1.14) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain==0.1.14) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.30 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain==0.1.14) (0.0.31)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.37 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain==0.1.14) (0.1.53)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain==0.1.14) (0.0.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain==0.1.14) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain==0.1.14) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain==0.1.14) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain==0.1.14) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain==0.1.14) (8.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.14) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.14) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.14) (3.0.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain-core<0.2.0,>=0.1.37->langchain==0.1.14) (23.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from pydantic<3,>=1->langchain==0.1.14) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from pydantic<3,>=1->langchain==0.1.14) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from pydantic<3,>=1->langchain==0.1.14) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.1.14) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.1.14) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.1.14) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from requests<3,>=2->langchain==0.1.14) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.14) (3.1.1)\n",
      "Requirement already satisfied: anyio in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.14) (1.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from yarl<2.0,>=1.0->aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (0.2.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain==0.1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community==0.0.31\n",
      "  Downloading langchain_community-0.0.31-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain-community==0.0.31) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain-community==0.0.31) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain-community==0.0.31) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain-community==0.0.31) (0.6.7)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.37 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain-community==0.0.31) (0.1.53)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain-community==0.0.31) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain-community==0.0.31) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain-community==0.0.31) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain-community==0.0.31) (8.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.31) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.31) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.31) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.31) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.31) (1.18.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.31) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.31) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.31) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain-core<0.2.0,>=0.1.37->langchain-community==0.0.31) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain-core<0.2.0,>=0.1.37->langchain-community==0.0.31) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langchain-core<0.2.0,>=0.1.37->langchain-community==0.0.31) (2.9.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.0.31) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.0.31) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.0.31) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from requests<3,>=2->langchain-community==0.0.31) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from requests<3,>=2->langchain-community==0.0.31) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from requests<3,>=2->langchain-community==0.0.31) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from requests<3,>=2->langchain-community==0.0.31) (2024.8.30)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.31) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.31) (3.1.1)\n",
      "Requirement already satisfied: anyio in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.31) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.31) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.31) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.37->langchain-community==0.0.31) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.37->langchain-community==0.0.31) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.37->langchain-community==0.0.31) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.31) (1.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from yarl<2.0,>=1.0->aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.31) (0.2.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.31) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.31) (1.3.1)\n",
      "Downloading langchain_community-0.0.31-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langchain-community\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.0.38\n",
      "    Uninstalling langchain-community-0.0.38:\n",
      "      Successfully uninstalled langchain-community-0.0.38\n",
      "Successfully installed langchain-community-0.0.31\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-community==0.0.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from time import time\n",
    "import glob\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Json Doc fils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_file/final_data.json\n",
      "data_file/chroma.sqlite3\n",
      "data_file/08fd7bc2-8cb7-4211-9c66-dc29991c1dcc/index_metadata.pickle\n",
      "data_file/08fd7bc2-8cb7-4211-9c66-dc29991c1dcc/header.bin\n",
      "data_file/08fd7bc2-8cb7-4211-9c66-dc29991c1dcc/link_lists.bin\n",
      "data_file/08fd7bc2-8cb7-4211-9c66-dc29991c1dcc/data_level0.bin\n",
      "data_file/08fd7bc2-8cb7-4211-9c66-dc29991c1dcc/length.bin\n",
      "Loaded 2 docs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for dirname, _, filenames in os.walk('data_file'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "reader = SimpleDirectoryReader(input_dir=\"data_file/\", recursive=False)\n",
    "documents = reader.load_data()\n",
    "time_start = time()\n",
    "time_end = time()\n",
    "print(f\"Loaded {len(documents)} docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 1.0967254638671875e-05 seconds\n",
      "Took 8.619553565979004 seconds\n"
     ]
    }
   ],
   "source": [
    "time_duration = time_end - time_start\n",
    "# report the duration\n",
    "print(f'Took {time_duration} seconds')\n",
    "\n",
    "documents = [doc.to_langchain_format() for doc in documents]\n",
    "#documents\n",
    "\n",
    "time_start = time()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=70)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "time_end = time()\n",
    "\n",
    "time_duration = time_end - time_start\n",
    "# report the duration\n",
    "print(f'Took {time_duration} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Embedings asa vector DB  Form Huging Face model (if not already created un commebnt the vector db  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m HuggingFaceEmbeddings(model_name\u001b[38;5;241m=\u001b[39mmodel_name, model_kwargs\u001b[38;5;241m=\u001b[39mmodel_kwargs)\n\u001b[1;32m      7\u001b[0m time_start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m----> 9\u001b[0m vectordb \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhnsw:space\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcosine\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_file/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m time_end \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m     13\u001b[0m time_duration \u001b[38;5;241m=\u001b[39m time_end \u001b[38;5;241m-\u001b[39m time_start\n",
      "File \u001b[0;32m~/miniconda3/envs/RAG/lib/python3.9/site-packages/langchain_community/vectorstores/chroma.py:778\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    776\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    777\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RAG/lib/python3.9/site-packages/langchain_community/vectorstores/chroma.py:742\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m         chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(\n\u001b[1;32m    737\u001b[0m             texts\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m [],\n\u001b[1;32m    738\u001b[0m             metadatas\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m batch[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    739\u001b[0m             ids\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    740\u001b[0m         )\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 742\u001b[0m     \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chroma_collection\n",
      "File \u001b[0;32m~/miniconda3/envs/RAG/lib/python3.9/site-packages/langchain_community/vectorstores/chroma.py:275\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 275\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "File \u001b[0;32m~/miniconda3/envs/RAG/lib/python3.9/site-packages/langchain_community/embeddings/huggingface.py:98\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     96\u001b[0m     sentence_transformers\u001b[38;5;241m.\u001b[39mSentenceTransformer\u001b[38;5;241m.\u001b[39mstop_multi_process_pool(pool)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_kwargs\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/miniconda3/envs/RAG/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:652\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[38;5;66;03m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[39;00m\n\u001b[1;32m    651\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m convert_to_numpy:\n\u001b[0;32m--> 652\u001b[0m                 embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    654\u001b[0m         all_embeddings\u001b[38;5;241m.\u001b[39mextend(embeddings)\n\u001b[1;32m    656\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m [all_embeddings[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39margsort(length_sorted_idx)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name =   \"sentence-transformers/all-mpnet-base-v2\"     #\"\"\n",
    "# model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model_kwargs = {\"device\": \"cuda\"}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
    "\n",
    "# time_start = time()\n",
    "\n",
    "# # vectordb = Chroma.from_documents(documents=texts, embedding=embeddings, collection_metadata={\"hnsw:space\": \"cosine\"}, persist_directory=\"data_file/\")\n",
    "\n",
    "# time_end = time()\n",
    "\n",
    "# time_duration = time_end - time_start\n",
    "# # report the duration\n",
    "# print(f'Took {time_duration} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_vector_store = Chroma(persist_directory=\"data_file/\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_dicts(list_of_dicts):\n",
    "    unique_dicts = []\n",
    "    seen_dicts = set()\n",
    "\n",
    "    for d in list_of_dicts:\n",
    "        # Convert the dictionary to a frozenset of items (since dictionaries are not hashable)\n",
    "        dict_representation = frozenset(d.items())\n",
    "\n",
    "        # Check if the dictionary representation is unique\n",
    "        if dict_representation not in seen_dicts:\n",
    "            unique_dicts.append(d)\n",
    "            seen_dicts.add(dict_representation)\n",
    "\n",
    "    return unique_dicts\n",
    "\n",
    "def vector_search_source(query ):\n",
    "    docs = load_vector_store.similarity_search_with_score(query=query, k=5)\n",
    "\n",
    "    print(\"Sources:\")\n",
    "    src = []\n",
    "    for meta in docs:\n",
    "        #print(list(list(list(meta)[0])[0])[1]) # content\n",
    "        keys = ['page_label','file_name'] # \"file_path\",\"file_type\" ,\"creation_date\"\n",
    "        src.append(dict(filter(lambda item:item[0] in keys , list(list(list(meta)[0])[1])[1].items()))) # source\n",
    "\n",
    "    sources = extract_unique_dicts(src)\n",
    "    sources = filter(None,sources)\n",
    "\n",
    "    for meta in sources:\n",
    "        print(meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='NETSOL\\\\u2019s suite of products and software services was conducted across its facilities in California, USA; London, England; Beijing, Chi- na; Sydney, Australia; and Lahore, Pakistan.\"', metadata={'creation_date': '2024-12-16', 'file_name': 'final_data.json', 'file_path': '/home/iml/assingment4/data_file/final_data.json', 'file_size': 1545030, 'file_type': 'application/json', 'last_modified_date': '2024-12-11'}),\n",
       " Document(page_content='},\\n        {\\n            \"type\": \"Title\",\\n            \"content\": \"The Company and its Operations\"\\n        },\\n        {\\n            \"type\": \"NarrativeText\",\\n            \"content\": \"NetSol Technologies Limited (\\\\u201dthe Company\\\\u201d), incorporated in Pakistan on August 22, 1996 under the repealed Companies Ordinance, 1984, (now The Companies Act, 2017) as a Private Company Limited by shares, was later on converted into Public Limited Company and subsequently listed on Pakistan Stock Exchange on August 26, 2005. The Company is domiciled in Pakistan and is principally engaged in the development and sale of computer software and allied services in Pakistan as well as abroad.\"', metadata={'creation_date': '2024-12-16', 'file_name': 'final_data.json', 'file_path': '/home/iml/assingment4/data_file/final_data.json', 'file_size': 1545030, 'file_type': 'application/json', 'last_modified_date': '2024-12-11'}),\n",
       " Document(page_content='},\\n        {\\n            \"type\": \"NarrativeText\",\\n            \"content\": \"In North America, NETSOL was a part of different events in both the United States as well as Canada. In the US, the company was present at the ELFA Operations and Technol- ogy Conference, the AFSA Annual Meeting, the ELFA Annual Convention, the Auto Finance Summit and the Open Silicon Valley Conference. our delegates also attended the American Financial Services Association (AFSA) Vehicle Finance Conference and the National Automobile Dealers Association (NADA) Show. Both these events were held in Las Vegas. The company also attended the Consumer Bankers Association (CBA) event - CBA Live in Washington DC.\"', metadata={'creation_date': '2024-12-16', 'file_name': 'final_data.json', 'file_path': '/home/iml/assingment4/data_file/final_data.json', 'file_size': 1545030, 'file_type': 'application/json', 'last_modified_date': '2024-12-11'})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = load_vector_store.as_retriever(search_kwargs = {\"k\": 3} )\n",
    "retriever.get_relevant_documents(\"what is netsol\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from transformers import (\n",
    "#   AutoTokenizer,\n",
    "#   AutoModelForCausalLM,\n",
    "#   BitsAndBytesConfig,\n",
    "#   pipeline\n",
    "# )\n",
    "\n",
    "from torch import cuda, bfloat16\n",
    "# import transformers\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "model_name =   \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "model_name , #\"falcon/rw-1b-instruct\",\n",
    "   trust_remote_code=True,\n",
    "torch_dtype=\"auto\"\n",
    ")\n",
    "model.eval()\n",
    "model.to('cuda:0')\n",
    "print(f\"Model loaded on {device}\")\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name) #\"falcon/tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModel\n",
    "# device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "# model_name = \"sentence-transformers/all-MiniLM-L6-v2\"  # For embeddings, not causal language modeling\n",
    "\n",
    "# # Load the model for sentence embeddings (AutoModel for embedding tasks)\n",
    "# model = AutoModel.from_pretrained(\n",
    "#     model_name,\n",
    "#     trust_remote_code=True,\n",
    "#     torch_dtype=\"auto\"  # Auto will handle dtype based on the device\n",
    "# )\n",
    "# model.eval()\n",
    "\n",
    "# model.to('cuda:0')\n",
    "# print(f\"Model loaded on {device}\")\n",
    "\n",
    "# tokenizer = transformers.AutoTokenizer.from_pretrained(model_name) #\"falcon/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.StopOnTokens at 0x7046887c77f0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "# gpt-j-6b is trained to add \"<|endoftext|>\" at the end of generations\n",
    "stop_token_ids = tokenizer.convert_tokens_to_ids([\"<|endoftext|>\"])\n",
    "\n",
    "# define custom stopping criteria object\n",
    "class StopOnTokens(StoppingCriteria):\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        for stop_id in stop_token_ids:\n",
    "            if input_ids[0][-1] == stop_id:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList([StopOnTokens()])\n",
    "stopping_criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text = transformers.pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    return_full_text=True,  # langchain expects the full text\n",
    "    task='text-generation',\n",
    "    device='cuda:0',\n",
    "    # we pass model parameters here too\n",
    "    stopping_criteria=stopping_criteria,  # without this model will ramble\n",
    "    temperature=0.01,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n",
    "    top_p=0.15,  # select from top tokens whose probability add up to 15%\n",
    "    top_k=0,  # select from top 0 tokens (because zero, relies on top_p)\n",
    "    max_new_tokens=1024,  # mex number of tokens to generate in the output\n",
    "    repetition_penalty=1.1 , # without this output begins repeating\n",
    "    do_sample=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"\\nDon't try to make up an answer, if you don't know just say that you don't know.\\nAnswer in the same language the question was asked.\\nUse only the following pieces of context to answer the question at the end.\\n\\n{context}\\n\\nQuestion: {question}\\n\\n\\nAnswer:\"), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7046887c75e0>))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=generate_text)\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Don't try to make up an answer, if you don't know just say that you don't know.\n",
    "Answer in the same language the question was asked.\n",
    "Use only the following pieces of context to answer the question at the end.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template = prompt_template,\n",
    "    input_variables = [\"context\", \"question\" ]\n",
    ")\n",
    "\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "llm_chain = LLMChain(prompt=PROMPT, llm=llm)\n",
    "llm_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = load_vector_store.as_retriever(search_kwargs = {\"k\": 3})\n",
    "\n",
    "qa_chain_without_mem = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\", # map_reduce, map_rerank, stuff, refine\n",
    "    retriever = retriever,\n",
    "    #chain_type_kwargs = {\"prompt\": PROMPT},\n",
    "    return_source_documents = True,\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_dicts(list_of_dicts):\n",
    "    unique_dicts = []\n",
    "    seen_dicts = set()\n",
    "\n",
    "    for d in list_of_dicts:\n",
    "        # Convert the dictionary to a frozenset of items (since dictionaries are not hashable)\n",
    "        dict_representation = frozenset(d.items())\n",
    "\n",
    "        # Check if the dictionary representation is unique\n",
    "        if dict_representation not in seen_dicts:\n",
    "            unique_dicts.append(d)\n",
    "            seen_dicts.add(dict_representation)\n",
    "\n",
    "    return unique_dicts\n",
    "\n",
    "def qa_post_processing(raw_result):\n",
    "\n",
    "    print(\"Answer\")\n",
    "\n",
    "    context = raw_result['result']\n",
    "    start_index = context.find(\"Helpful Answer:\")\n",
    "    extracted_string = context[start_index:].strip().replace(\"Helpful Answer: \" , \"\")\n",
    "    print(extracted_string)\n",
    "\n",
    "    print(\" \")\n",
    "    print(\"Sources:\")\n",
    "    src=[]\n",
    "    for meta in raw_result['source_documents']:\n",
    "        keys = ['page_label','file_name'] # \"file_path\",\"file_type\" ,\"creation_date\"\n",
    "        src.append(dict(filter(lambda item:item[0] in keys , list(list(meta)[1])[1].items()))) # source\n",
    "\n",
    "    sources = extract_unique_dicts(src)\n",
    "    sources = filter(None,sources)\n",
    "\n",
    "    for meta in sources:\n",
    "        print(meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iml/miniconda3/envs/RAG/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer\n",
      "I cannot determine a problem statement from the provided context. The text focuses on NETSOL's presence at various events and their commitment to innovation in the financial services industry.\n",
      " \n",
      "Sources:\n",
      "{'file_name': 'final_data.json'}\n"
     ]
    }
   ],
   "source": [
    "query1 = \"what is problem statement  netsol\"\n",
    "result1 = qa_chain_without_mem(query1)\n",
    "qa_post_processing(result1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
